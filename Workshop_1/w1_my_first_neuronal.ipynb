{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "funky-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "active-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./diabetes.csv', delimiter=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accomplished-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar la data\n",
    "X = data.iloc[:,0:8]\n",
    "y = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-newcastle",
   "metadata": {},
   "source": [
    "# Definir el modelo\n",
    "- Modelo secuencial\n",
    "- Capas complementamente, donde se define neuronas y las funciones de activacion de la capas intermedias\n",
    "- Definir la capa de salida y su funcion de activacion\n",
    "    * Capa de entrada de 8 entradas\n",
    "    * Capas ocultas de 12 neuronas (Funcion Relu) y 8 neuronas (Funcion Relu)\n",
    "    * Capa salida(Funcion activacion sigmoidea) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interested-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earlier-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-transition",
   "metadata": {},
   "source": [
    "- Establecer la función de perdida, para optimizar los pesos de la red (**pérdida algoritmica**)\n",
    "- Establecer alguna metrica de evaluación (Se utilizara accuracy, no es el mejor, ya que los datos estan desbalanceados, pero continuo con la finalidad de obtener resultados similares al profesor)\n",
    "- Gradiante descendente **ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impaired-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-speaking",
   "metadata": {},
   "source": [
    "# Ajustar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-forestry",
   "metadata": {},
   "source": [
    "- Iteraciones son epocas, donde se reconfiguran los pesos acorde a la funcion de perdida\n",
    "- Tambien se establece el numero de instancia, antes de actualizar los pesos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "miniature-highland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "48/48 [==============================] - 0s 596us/step - loss: 2.5846 - accuracy: 0.4682\n",
      "Epoch 2/150\n",
      "48/48 [==============================] - 0s 530us/step - loss: 1.1450 - accuracy: 0.5053\n",
      "Epoch 3/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.9278 - accuracy: 0.5441\n",
      "Epoch 4/150\n",
      "48/48 [==============================] - 0s 584us/step - loss: 0.9609 - accuracy: 0.5807\n",
      "Epoch 5/150\n",
      "48/48 [==============================] - 0s 571us/step - loss: 0.9258 - accuracy: 0.5538\n",
      "Epoch 6/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.9128 - accuracy: 0.5696\n",
      "Epoch 7/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.8459 - accuracy: 0.5920\n",
      "Epoch 8/150\n",
      "48/48 [==============================] - 0s 658us/step - loss: 0.8040 - accuracy: 0.5895\n",
      "Epoch 9/150\n",
      "48/48 [==============================] - 0s 701us/step - loss: 0.7856 - accuracy: 0.6091\n",
      "Epoch 10/150\n",
      "48/48 [==============================] - 0s 673us/step - loss: 0.7898 - accuracy: 0.5790\n",
      "Epoch 11/150\n",
      "48/48 [==============================] - 0s 648us/step - loss: 0.7219 - accuracy: 0.6233\n",
      "Epoch 12/150\n",
      "48/48 [==============================] - 0s 603us/step - loss: 0.6837 - accuracy: 0.6550\n",
      "Epoch 13/150\n",
      "48/48 [==============================] - 0s 615us/step - loss: 0.6550 - accuracy: 0.6726\n",
      "Epoch 14/150\n",
      "48/48 [==============================] - 0s 633us/step - loss: 0.6770 - accuracy: 0.6607\n",
      "Epoch 15/150\n",
      "48/48 [==============================] - 0s 625us/step - loss: 0.6505 - accuracy: 0.6544\n",
      "Epoch 16/150\n",
      "48/48 [==============================] - 0s 638us/step - loss: 0.6764 - accuracy: 0.6491\n",
      "Epoch 17/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.6703 - accuracy: 0.6625\n",
      "Epoch 18/150\n",
      "48/48 [==============================] - 0s 637us/step - loss: 0.6393 - accuracy: 0.6627\n",
      "Epoch 19/150\n",
      "48/48 [==============================] - 0s 637us/step - loss: 0.6413 - accuracy: 0.6706\n",
      "Epoch 20/150\n",
      "48/48 [==============================] - 0s 648us/step - loss: 0.6357 - accuracy: 0.6604\n",
      "Epoch 21/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.6231 - accuracy: 0.6552\n",
      "Epoch 22/150\n",
      "48/48 [==============================] - 0s 637us/step - loss: 0.6003 - accuracy: 0.7001\n",
      "Epoch 23/150\n",
      "48/48 [==============================] - 0s 629us/step - loss: 0.5818 - accuracy: 0.6908\n",
      "Epoch 24/150\n",
      "48/48 [==============================] - 0s 626us/step - loss: 0.5950 - accuracy: 0.6929\n",
      "Epoch 25/150\n",
      "48/48 [==============================] - 0s 615us/step - loss: 0.5664 - accuracy: 0.7306\n",
      "Epoch 26/150\n",
      "48/48 [==============================] - 0s 615us/step - loss: 0.6022 - accuracy: 0.6855\n",
      "Epoch 27/150\n",
      "48/48 [==============================] - 0s 638us/step - loss: 0.5881 - accuracy: 0.6766\n",
      "Epoch 28/150\n",
      "48/48 [==============================] - 0s 733us/step - loss: 0.5914 - accuracy: 0.6887\n",
      "Epoch 29/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5909 - accuracy: 0.6996\n",
      "Epoch 30/150\n",
      "48/48 [==============================] - 0s 609us/step - loss: 0.5997 - accuracy: 0.6741\n",
      "Epoch 31/150\n",
      "48/48 [==============================] - 0s 636us/step - loss: 0.5598 - accuracy: 0.7189\n",
      "Epoch 32/150\n",
      "48/48 [==============================] - 0s 637us/step - loss: 0.5629 - accuracy: 0.7075\n",
      "Epoch 33/150\n",
      "48/48 [==============================] - 0s 679us/step - loss: 0.5803 - accuracy: 0.7052\n",
      "Epoch 34/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5665 - accuracy: 0.6850\n",
      "Epoch 35/150\n",
      "48/48 [==============================] - 0s 615us/step - loss: 0.5563 - accuracy: 0.7135\n",
      "Epoch 36/150\n",
      "48/48 [==============================] - 0s 620us/step - loss: 0.5748 - accuracy: 0.6932\n",
      "Epoch 37/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5971 - accuracy: 0.6960\n",
      "Epoch 38/150\n",
      "48/48 [==============================] - 0s 583us/step - loss: 0.5627 - accuracy: 0.7036\n",
      "Epoch 39/150\n",
      "48/48 [==============================] - 0s 628us/step - loss: 0.5829 - accuracy: 0.6833\n",
      "Epoch 40/150\n",
      "48/48 [==============================] - 0s 637us/step - loss: 0.5925 - accuracy: 0.6947\n",
      "Epoch 41/150\n",
      "48/48 [==============================] - 0s 764us/step - loss: 0.5588 - accuracy: 0.6851\n",
      "Epoch 42/150\n",
      "48/48 [==============================] - 0s 599us/step - loss: 0.5523 - accuracy: 0.7241\n",
      "Epoch 43/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.5700 - accuracy: 0.6947\n",
      "Epoch 44/150\n",
      "48/48 [==============================] - 0s 630us/step - loss: 0.5466 - accuracy: 0.7298\n",
      "Epoch 45/150\n",
      "48/48 [==============================] - 0s 649us/step - loss: 0.5580 - accuracy: 0.7069\n",
      "Epoch 46/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5530 - accuracy: 0.7270\n",
      "Epoch 47/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5523 - accuracy: 0.7189\n",
      "Epoch 48/150\n",
      "48/48 [==============================] - 0s 591us/step - loss: 0.5513 - accuracy: 0.7142\n",
      "Epoch 49/150\n",
      "48/48 [==============================] - 0s 530us/step - loss: 0.5563 - accuracy: 0.7248\n",
      "Epoch 50/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5435 - accuracy: 0.7056\n",
      "Epoch 51/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5239 - accuracy: 0.7658\n",
      "Epoch 52/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5475 - accuracy: 0.7252\n",
      "Epoch 53/150\n",
      "48/48 [==============================] - 0s 531us/step - loss: 0.5762 - accuracy: 0.7068\n",
      "Epoch 54/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5453 - accuracy: 0.6907\n",
      "Epoch 55/150\n",
      "48/48 [==============================] - 0s 564us/step - loss: 0.4997 - accuracy: 0.7537\n",
      "Epoch 56/150\n",
      "48/48 [==============================] - 0s 551us/step - loss: 0.5437 - accuracy: 0.7351\n",
      "Epoch 57/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5616 - accuracy: 0.7011\n",
      "Epoch 58/150\n",
      "48/48 [==============================] - 0s 595us/step - loss: 0.5207 - accuracy: 0.7248\n",
      "Epoch 59/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5279 - accuracy: 0.7434\n",
      "Epoch 60/150\n",
      "48/48 [==============================] - 0s 572us/step - loss: 0.5469 - accuracy: 0.7266\n",
      "Epoch 61/150\n",
      "48/48 [==============================] - 0s 530us/step - loss: 0.5161 - accuracy: 0.7504\n",
      "Epoch 62/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5437 - accuracy: 0.7242\n",
      "Epoch 63/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5386 - accuracy: 0.7432\n",
      "Epoch 64/150\n",
      "48/48 [==============================] - 0s 574us/step - loss: 0.5360 - accuracy: 0.7325\n",
      "Epoch 65/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5626 - accuracy: 0.7086\n",
      "Epoch 66/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5221 - accuracy: 0.7340\n",
      "Epoch 67/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5641 - accuracy: 0.7119\n",
      "Epoch 68/150\n",
      "48/48 [==============================] - 0s 563us/step - loss: 0.4977 - accuracy: 0.7594\n",
      "Epoch 69/150\n",
      "48/48 [==============================] - 0s 575us/step - loss: 0.5394 - accuracy: 0.7280\n",
      "Epoch 70/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.5115 - accuracy: 0.7356\n",
      "Epoch 71/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4968 - accuracy: 0.7629\n",
      "Epoch 72/150\n",
      "48/48 [==============================] - 0s 550us/step - loss: 0.4942 - accuracy: 0.7550\n",
      "Epoch 73/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5453 - accuracy: 0.7213\n",
      "Epoch 74/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.4859 - accuracy: 0.7879\n",
      "Epoch 75/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5401 - accuracy: 0.7237\n",
      "Epoch 76/150\n",
      "48/48 [==============================] - 0s 641us/step - loss: 0.5339 - accuracy: 0.7258\n",
      "Epoch 77/150\n",
      "48/48 [==============================] - 0s 589us/step - loss: 0.5789 - accuracy: 0.6988\n",
      "Epoch 78/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5687 - accuracy: 0.7274\n",
      "Epoch 79/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.5378 - accuracy: 0.7274\n",
      "Epoch 80/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5105 - accuracy: 0.7488\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 573us/step - loss: 0.4952 - accuracy: 0.7519\n",
      "Epoch 82/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.5048 - accuracy: 0.7381\n",
      "Epoch 83/150\n",
      "48/48 [==============================] - 0s 553us/step - loss: 0.5087 - accuracy: 0.7424\n",
      "Epoch 84/150\n",
      "48/48 [==============================] - 0s 560us/step - loss: 0.5094 - accuracy: 0.7675\n",
      "Epoch 85/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.5032 - accuracy: 0.7584\n",
      "Epoch 86/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.4829 - accuracy: 0.7798\n",
      "Epoch 87/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.5457 - accuracy: 0.6981\n",
      "Epoch 88/150\n",
      "48/48 [==============================] - 0s 563us/step - loss: 0.4925 - accuracy: 0.7436\n",
      "Epoch 89/150\n",
      "48/48 [==============================] - 0s 530us/step - loss: 0.4884 - accuracy: 0.7712\n",
      "Epoch 90/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.4826 - accuracy: 0.7711\n",
      "Epoch 91/150\n",
      "48/48 [==============================] - 0s 613us/step - loss: 0.5210 - accuracy: 0.7389\n",
      "Epoch 92/150\n",
      "48/48 [==============================] - 0s 564us/step - loss: 0.4968 - accuracy: 0.7635\n",
      "Epoch 93/150\n",
      "48/48 [==============================] - 0s 584us/step - loss: 0.5077 - accuracy: 0.7437\n",
      "Epoch 94/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5029 - accuracy: 0.7553\n",
      "Epoch 95/150\n",
      "48/48 [==============================] - 0s 530us/step - loss: 0.5605 - accuracy: 0.7155\n",
      "Epoch 96/150\n",
      "48/48 [==============================] - 0s 615us/step - loss: 0.5129 - accuracy: 0.7515\n",
      "Epoch 97/150\n",
      "48/48 [==============================] - 0s 617us/step - loss: 0.4847 - accuracy: 0.7758\n",
      "Epoch 98/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5130 - accuracy: 0.7574\n",
      "Epoch 99/150\n",
      "48/48 [==============================] - 0s 571us/step - loss: 0.5142 - accuracy: 0.7508\n",
      "Epoch 100/150\n",
      "48/48 [==============================] - 0s 560us/step - loss: 0.5103 - accuracy: 0.7668\n",
      "Epoch 101/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4799 - accuracy: 0.7784\n",
      "Epoch 102/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5249 - accuracy: 0.7360\n",
      "Epoch 103/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4917 - accuracy: 0.7671\n",
      "Epoch 104/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5328 - accuracy: 0.7238\n",
      "Epoch 105/150\n",
      "48/48 [==============================] - 0s 578us/step - loss: 0.5001 - accuracy: 0.7525\n",
      "Epoch 106/150\n",
      "48/48 [==============================] - 0s 594us/step - loss: 0.4789 - accuracy: 0.7759\n",
      "Epoch 107/150\n",
      "48/48 [==============================] - 0s 574us/step - loss: 0.5186 - accuracy: 0.7139\n",
      "Epoch 108/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5045 - accuracy: 0.7424\n",
      "Epoch 109/150\n",
      "48/48 [==============================] - 0s 649us/step - loss: 0.4873 - accuracy: 0.7424\n",
      "Epoch 110/150\n",
      "48/48 [==============================] - 0s 587us/step - loss: 0.4759 - accuracy: 0.7967\n",
      "Epoch 111/150\n",
      "48/48 [==============================] - 0s 679us/step - loss: 0.4948 - accuracy: 0.7539\n",
      "Epoch 112/150\n",
      "48/48 [==============================] - 0s 664us/step - loss: 0.5261 - accuracy: 0.7293\n",
      "Epoch 113/150\n",
      "48/48 [==============================] - 0s 622us/step - loss: 0.5176 - accuracy: 0.7361\n",
      "Epoch 114/150\n",
      "48/48 [==============================] - 0s 637us/step - loss: 0.5069 - accuracy: 0.7616\n",
      "Epoch 115/150\n",
      "48/48 [==============================] - 0s 636us/step - loss: 0.5016 - accuracy: 0.7538\n",
      "Epoch 116/150\n",
      "48/48 [==============================] - 0s 619us/step - loss: 0.5341 - accuracy: 0.7250\n",
      "Epoch 117/150\n",
      "48/48 [==============================] - 0s 616us/step - loss: 0.4664 - accuracy: 0.7845\n",
      "Epoch 118/150\n",
      "48/48 [==============================] - 0s 595us/step - loss: 0.5422 - accuracy: 0.7323\n",
      "Epoch 119/150\n",
      "48/48 [==============================] - 0s 580us/step - loss: 0.4962 - accuracy: 0.7545\n",
      "Epoch 120/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5145 - accuracy: 0.7528\n",
      "Epoch 121/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4807 - accuracy: 0.7595\n",
      "Epoch 122/150\n",
      "48/48 [==============================] - 0s 592us/step - loss: 0.4952 - accuracy: 0.7572\n",
      "Epoch 123/150\n",
      "48/48 [==============================] - 0s 599us/step - loss: 0.4738 - accuracy: 0.7611\n",
      "Epoch 124/150\n",
      "48/48 [==============================] - 0s 574us/step - loss: 0.5151 - accuracy: 0.7386\n",
      "Epoch 125/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5016 - accuracy: 0.7572\n",
      "Epoch 126/150\n",
      "48/48 [==============================] - 0s 639us/step - loss: 0.5129 - accuracy: 0.7610\n",
      "Epoch 127/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5071 - accuracy: 0.7441\n",
      "Epoch 128/150\n",
      "48/48 [==============================] - 0s 614us/step - loss: 0.4673 - accuracy: 0.7769\n",
      "Epoch 129/150\n",
      "48/48 [==============================] - 0s 595us/step - loss: 0.5059 - accuracy: 0.7556\n",
      "Epoch 130/150\n",
      "48/48 [==============================] - 0s 572us/step - loss: 0.4698 - accuracy: 0.7905\n",
      "Epoch 131/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4833 - accuracy: 0.7774\n",
      "Epoch 132/150\n",
      "48/48 [==============================] - 0s 595us/step - loss: 0.5184 - accuracy: 0.7516\n",
      "Epoch 133/150\n",
      "48/48 [==============================] - 0s 589us/step - loss: 0.5107 - accuracy: 0.7582\n",
      "Epoch 134/150\n",
      "48/48 [==============================] - 0s 568us/step - loss: 0.4780 - accuracy: 0.7622\n",
      "Epoch 135/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4790 - accuracy: 0.7797\n",
      "Epoch 136/150\n",
      "48/48 [==============================] - 0s 583us/step - loss: 0.5407 - accuracy: 0.6999\n",
      "Epoch 137/150\n",
      "48/48 [==============================] - 0s 593us/step - loss: 0.4959 - accuracy: 0.7530\n",
      "Epoch 138/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4971 - accuracy: 0.7557\n",
      "Epoch 139/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.4817 - accuracy: 0.7797\n",
      "Epoch 140/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.4640 - accuracy: 0.7696\n",
      "Epoch 141/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4987 - accuracy: 0.7488\n",
      "Epoch 142/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5210 - accuracy: 0.7383\n",
      "Epoch 143/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4922 - accuracy: 0.7380\n",
      "Epoch 144/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.5136 - accuracy: 0.7610\n",
      "Epoch 145/150\n",
      "48/48 [==============================] - 0s 679us/step - loss: 0.4990 - accuracy: 0.7553\n",
      "Epoch 146/150\n",
      "48/48 [==============================] - 0s 606us/step - loss: 0.4771 - accuracy: 0.7781\n",
      "Epoch 147/150\n",
      "48/48 [==============================] - 0s 586us/step - loss: 0.5020 - accuracy: 0.7577\n",
      "Epoch 148/150\n",
      "48/48 [==============================] - 0s 552us/step - loss: 0.5120 - accuracy: 0.7605\n",
      "Epoch 149/150\n",
      "48/48 [==============================] - 0s 573us/step - loss: 0.4879 - accuracy: 0.7666\n",
      "Epoch 150/150\n",
      "48/48 [==============================] - 0s 592us/step - loss: 0.4833 - accuracy: 0.7644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d36105550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=150, batch_size = 16, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-ballet",
   "metadata": {},
   "source": [
    "# Evaluar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "compliant-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 694us/step - loss: 0.5034 - accuracy: 0.7513\n",
      "Accuracy: 75.13\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X,y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-mapping",
   "metadata": {},
   "source": [
    "# Hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "related-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(X) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "leading-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] --> 1 (real 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.35100000000000003, 31.0] --> 0 (real 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] --> 1 (real 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.16699999999999998, 21.0] --> 0 (real 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.2880000000000003, 33.0] --> 1 (real 1)\n",
      "[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] --> 0 (real 0)\n",
      "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] --> 0 (real 1)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] --> 1 (real 0)\n",
      "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] --> 0 (real 1)\n",
      "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.23199999999999998, 54.0] --> 0 (real 1)\n",
      "[4.0, 110.0, 92.0, 0.0, 0.0, 37.6, 0.191, 30.0] --> 0 (real 0)\n",
      "[10.0, 168.0, 74.0, 0.0, 0.0, 38.0, 0.537, 34.0] --> 1 (real 1)\n",
      "[10.0, 139.0, 80.0, 0.0, 0.0, 27.1, 1.4409999999999998, 57.0] --> 1 (real 0)\n",
      "[1.0, 189.0, 60.0, 23.0, 846.0, 30.1, 0.39799999999999996, 59.0] --> 1 (real 1)\n",
      "[5.0, 166.0, 72.0, 19.0, 175.0, 25.8, 0.5870000000000001, 51.0] --> 0 (real 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('%s --> %d (real %d)' % (X.iloc[i].tolist(), predictions[i], y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
