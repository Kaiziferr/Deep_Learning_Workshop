{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "funky-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "active-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./diabetes.csv', delimiter=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accomplished-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:8]\n",
    "y = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-newcastle",
   "metadata": {},
   "source": [
    "# Definir el modelo\n",
    "- Modelo secuencial\n",
    "- Capas complementamente, donde se define neuronas y las funciones de activacion de la capas intermedias\n",
    "- Definir la capa de salida y su funcion de activacion\n",
    "    * Capa de entrada de 8 entradas\n",
    "    * Capas ocultas de 12 neuronas (Funcion Relu) y 8 neuronas (Funcion Relu)\n",
    "    * Capa salida(Funcion activacion sigmoidea) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "interested-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "earlier-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-transition",
   "metadata": {},
   "source": [
    "- Establecer la función de perdida, para optimizar los pesos de la red (**pérdida algoritmica**)\n",
    "- Establecer alguna metrica de evaluación (Se utilizara accuracy, no es el mejor, ya que los datos estan desbalanceados, pero continuo con la finalidad de obtener resultados similares al profesor)\n",
    "- Gradiante descendente **ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impaired-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-speaking",
   "metadata": {},
   "source": [
    "# Ajustar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-forestry",
   "metadata": {},
   "source": [
    "- Iteraciones son epocas, donde se reconfiguran los pesos acorde a la funcion de perdida\n",
    "- Tambien se establece el numero de instancia, antes de actualizar los pesos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "miniature-highland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 45.0995 - accuracy: 0.3211\n",
      "Epoch 2/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.0472 - accuracy: 0.3624\n",
      "Epoch 3/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.1502 - accuracy: 0.3553\n",
      "Epoch 4/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2870 - accuracy: 0.5113\n",
      "Epoch 5/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2302 - accuracy: 0.6074\n",
      "Epoch 6/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8914 - accuracy: 0.6186\n",
      "Epoch 7/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8217 - accuracy: 0.6254\n",
      "Epoch 8/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7633 - accuracy: 0.6103\n",
      "Epoch 9/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.6117\n",
      "Epoch 10/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6741\n",
      "Epoch 11/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6290\n",
      "Epoch 12/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6394\n",
      "Epoch 13/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6574\n",
      "Epoch 14/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6561\n",
      "Epoch 15/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6407\n",
      "Epoch 16/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6328\n",
      "Epoch 17/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6116\n",
      "Epoch 18/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6736\n",
      "Epoch 19/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6474\n",
      "Epoch 20/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6599\n",
      "Epoch 21/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.7054\n",
      "Epoch 22/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6620\n",
      "Epoch 23/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6823\n",
      "Epoch 24/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6457\n",
      "Epoch 25/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6576\n",
      "Epoch 26/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6671\n",
      "Epoch 27/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6736\n",
      "Epoch 28/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6587\n",
      "Epoch 29/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6482\n",
      "Epoch 30/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6818\n",
      "Epoch 31/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6585\n",
      "Epoch 32/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6506\n",
      "Epoch 33/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6807\n",
      "Epoch 34/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6899\n",
      "Epoch 35/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6703\n",
      "Epoch 36/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.6964\n",
      "Epoch 37/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6778\n",
      "Epoch 38/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7120\n",
      "Epoch 39/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7057: 0s - loss: 0.5690 - accuracy: 0.70\n",
      "Epoch 40/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6833\n",
      "Epoch 41/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7021\n",
      "Epoch 42/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6415\n",
      "Epoch 43/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6805\n",
      "Epoch 44/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.6897\n",
      "Epoch 45/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7083\n",
      "Epoch 46/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.6891\n",
      "Epoch 47/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7138\n",
      "Epoch 48/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6905\n",
      "Epoch 49/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.6987\n",
      "Epoch 50/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6880\n",
      "Epoch 51/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6998\n",
      "Epoch 52/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7087\n",
      "Epoch 53/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.6879\n",
      "Epoch 54/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6759\n",
      "Epoch 55/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6796\n",
      "Epoch 56/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6764\n",
      "Epoch 57/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.6942\n",
      "Epoch 58/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7042\n",
      "Epoch 59/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.6693\n",
      "Epoch 60/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7064\n",
      "Epoch 61/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6851\n",
      "Epoch 62/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6668\n",
      "Epoch 63/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.6433\n",
      "Epoch 64/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6925\n",
      "Epoch 65/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.6966\n",
      "Epoch 66/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.6983\n",
      "Epoch 67/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6781\n",
      "Epoch 68/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7044\n",
      "Epoch 69/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7109\n",
      "Epoch 70/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.6530\n",
      "Epoch 71/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6970\n",
      "Epoch 72/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.6958\n",
      "Epoch 73/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.6942\n",
      "Epoch 74/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6830\n",
      "Epoch 75/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.6916\n",
      "Epoch 76/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5544 - accuracy: 0.7101\n",
      "Epoch 77/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.6779\n",
      "Epoch 78/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.6929\n",
      "Epoch 79/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7068\n",
      "Epoch 80/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7274\n",
      "Epoch 81/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6797\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7325\n",
      "Epoch 83/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6817\n",
      "Epoch 84/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7026\n",
      "Epoch 85/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7169\n",
      "Epoch 86/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7081\n",
      "Epoch 87/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.6927\n",
      "Epoch 88/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7023\n",
      "Epoch 89/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.6974\n",
      "Epoch 90/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7186\n",
      "Epoch 91/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.6905\n",
      "Epoch 92/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6771\n",
      "Epoch 93/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.6907\n",
      "Epoch 94/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7100\n",
      "Epoch 95/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7114\n",
      "Epoch 96/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7264\n",
      "Epoch 97/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.6939\n",
      "Epoch 98/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.6972\n",
      "Epoch 99/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7154\n",
      "Epoch 100/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6945\n",
      "Epoch 101/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7095\n",
      "Epoch 102/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.6925\n",
      "Epoch 103/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7181\n",
      "Epoch 104/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7223\n",
      "Epoch 105/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7161\n",
      "Epoch 106/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.6989\n",
      "Epoch 107/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7189\n",
      "Epoch 108/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7231\n",
      "Epoch 109/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7466\n",
      "Epoch 110/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7240\n",
      "Epoch 111/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7192\n",
      "Epoch 112/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7219\n",
      "Epoch 113/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7171\n",
      "Epoch 114/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7440\n",
      "Epoch 115/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7635\n",
      "Epoch 116/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7323\n",
      "Epoch 117/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7240\n",
      "Epoch 118/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7463\n",
      "Epoch 119/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7165\n",
      "Epoch 120/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7290\n",
      "Epoch 121/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7119\n",
      "Epoch 122/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7360\n",
      "Epoch 123/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7563\n",
      "Epoch 124/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7328\n",
      "Epoch 125/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7221\n",
      "Epoch 126/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7294\n",
      "Epoch 127/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7163\n",
      "Epoch 128/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7364\n",
      "Epoch 129/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7173\n",
      "Epoch 130/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7247\n",
      "Epoch 131/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7282\n",
      "Epoch 132/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7486\n",
      "Epoch 133/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7471\n",
      "Epoch 134/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7490\n",
      "Epoch 135/150\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7674\n",
      "Epoch 136/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7373\n",
      "Epoch 137/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7406\n",
      "Epoch 138/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7671\n",
      "Epoch 139/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7263\n",
      "Epoch 140/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7097\n",
      "Epoch 141/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7779\n",
      "Epoch 142/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7259\n",
      "Epoch 143/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7329\n",
      "Epoch 144/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7427\n",
      "Epoch 145/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7281\n",
      "Epoch 146/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7280\n",
      "Epoch 147/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7258\n",
      "Epoch 148/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7291\n",
      "Epoch 149/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7633\n",
      "Epoch 150/150\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205800ba710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=150, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-ballet",
   "metadata": {},
   "source": [
    "# Evaluar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "compliant-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7214\n",
      "Accuracy: 72.14\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X,y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-mapping",
   "metadata": {},
   "source": [
    "# Hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "related-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(X) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "leading-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] --> 1 (real 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.35100000000000003, 31.0] --> 0 (real 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] --> 1 (real 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.16699999999999998, 21.0] --> 0 (real 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.2880000000000003, 33.0] --> 1 (real 1)\n",
      "[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] --> 0 (real 0)\n",
      "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] --> 0 (real 1)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] --> 1 (real 0)\n",
      "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] --> 1 (real 1)\n",
      "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.23199999999999998, 54.0] --> 0 (real 1)\n",
      "[4.0, 110.0, 92.0, 0.0, 0.0, 37.6, 0.191, 30.0] --> 0 (real 0)\n",
      "[10.0, 168.0, 74.0, 0.0, 0.0, 38.0, 0.537, 34.0] --> 1 (real 1)\n",
      "[10.0, 139.0, 80.0, 0.0, 0.0, 27.1, 1.4409999999999998, 57.0] --> 1 (real 0)\n",
      "[1.0, 189.0, 60.0, 23.0, 846.0, 30.1, 0.39799999999999996, 59.0] --> 1 (real 1)\n",
      "[5.0, 166.0, 72.0, 19.0, 175.0, 25.8, 0.5870000000000001, 51.0] --> 1 (real 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('%s --> %d (real %d)' % (X.iloc[i].tolist(), predictions[i], y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
